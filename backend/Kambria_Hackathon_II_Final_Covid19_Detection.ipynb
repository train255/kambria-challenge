{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "xyFTmjeHdFWd"
      },
      "outputs": [],
      "source": [
        "%cd /content/\n",
        "!gdown https://drive.google.com/uc?id=1Oq9UgA9cEGMNRGvF7oNKkFOg6udsDprl"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "dETcufl_jBoJ"
      },
      "outputs": [],
      "source": [
        "!mkdir -p /content/final_public_train\n",
        "%cd '/content/aicv115m_final_public_train/public_train_audio_files/'\n",
        "!for i in *.wav; do name=`echo \"${i%.*}\"` ; ffmpeg -y -i \"${name}.wav\" -ar 16000 -ac 1 \"/content/final_public_train/${name}.wav\"; done"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "GLdlaK5JdZdz"
      },
      "outputs": [],
      "source": [
        "import librosa\n",
        "import librosa.display\n",
        "from tqdm import tqdm\n",
        "\n",
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization, Dropout, Conv2D, Dense, GlobalAveragePooling2D, concatenate\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.utils import plot_model, Sequence\n",
        "\n",
        "from datetime import datetime\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "import itertools\n",
        "import pylab\n",
        "from shutil import copyfile"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "p9P_m_uudYos"
      },
      "outputs": [],
      "source": [
        "train_meta_df = pd.read_csv(\"/content/aicv115m_final_public_train/public_train_metadata.csv\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hFBEX2RGeZA7"
      },
      "outputs": [],
      "source": [
        "train_audio_dir = \"/content/final_public_train/\"\n",
        "train_meta_df[\"audio_path\"] = train_meta_df[\"uuid\"].apply(lambda x: train_audio_dir + x + \".wav\")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "iag928bgecJZ"
      },
      "outputs": [],
      "source": [
        "train_meta_df.drop(train_meta_df[train_meta_df['uuid'] == \"23ccaa28-8cb8-43e4-9e59-112fa4dc6559\"].index, inplace = True)\n",
        "idx_lst = [169, 1063, 2064, 2297, 2512, 2723, 2832, 3143, 3600, 3774, 3820, 4191, 4378]\n",
        "df_covid = train_meta_df.iloc[idx_lst][[\"uuid\",\"assessment_result\", \"audio_path\"]].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "lfMAhgOBejUj"
      },
      "outputs": [],
      "source": [
        "train_nonote_df = train_meta_df[train_meta_df.audio_noise_note.isnull()].reset_index(drop=True)\n",
        "train_nonote_df = train_nonote_df[[\"uuid\",\"assessment_result\", \"audio_path\"]]"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mjIbp4KYen3R"
      },
      "outputs": [],
      "source": [
        "train_data = pd.concat([train_nonote_df, df_covid]).reset_index(drop=True)\n",
        "train_data = train_data[[\"uuid\",\"assessment_result\", \"audio_path\"]]"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "wgGaMUj3fFM9"
      },
      "source": [
        "### Get audio <= 6.13 seconds"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AzVs58XKetOp"
      },
      "outputs": [],
      "source": [
        "# Get duration and sample rate\n",
        "import scipy\n",
        "from scipy.io import wavfile\n",
        "\n",
        "def getRateAndDuration(_df):\n",
        "    sample_rate_lst = []\n",
        "    seconds_lst = []\n",
        "    for index, row in _df.iterrows():\n",
        "        sample_rate, data = wavfile.read(row[\"audio_path\"])\n",
        "        sample_rate_lst.append(sample_rate)\n",
        "        len_data = len(data)  # holds length of the numpy array\n",
        "        t = len_data / sample_rate  # returns duration but in floats\n",
        "        seconds_lst.append(t)\n",
        "    _df[\"sample_rate\"] = sample_rate_lst\n",
        "    _df[\"seconds\"] = seconds_lst\n",
        "    return _df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "TmELn3gMexue"
      },
      "outputs": [],
      "source": [
        "train_data = getRateAndDuration(train_data)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "7F_eEqL4URnv"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/cough_data\n",
        "!mkdir -p /content/cough_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "V2kSKur7T-jI"
      },
      "outputs": [],
      "source": [
        "tmp_df = train_data[(train_data[\"seconds\"] <= 6.13)].reset_index(drop=True)\n",
        "\n",
        "for index, row in tmp_df.iterrows():\n",
        "    src = row[\"audio_path\"]\n",
        "    dst = \"/content/cough_data/\"+row[\"uuid\"]+\".wav\"\n",
        "    copyfile(src, dst)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_pWbeyvMfqAw"
      },
      "outputs": [],
      "source": [
        "!pip install pydub"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "UNwQHw12fxSi"
      },
      "outputs": [],
      "source": [
        "from pydub import AudioSegment\n",
        "from pydub.silence import split_on_silence, detect_nonsilent\n",
        "import os\n",
        "\n",
        "def splitAudio(new_covid_data, file_path, assessment_result, dst_pth, min_silence_len, keep_silence):\n",
        "    file_name = os.path.basename(file_path)\n",
        "    sound_file = AudioSegment.from_wav(file_path)\n",
        "    audio_chunks = split_on_silence(sound_file, min_silence_len=min_silence_len, silence_thresh=sound_file.dBFS-16, keep_silence=keep_silence)\n",
        "    for i, chunk in enumerate(audio_chunks):\n",
        "        uuid = \"chunk\" + str(i) + file_name.split(\".\")[0]\n",
        "        out_file = dst_pth + uuid + \".wav\"\n",
        "        chunk.export(out_file, format=\"wav\")\n",
        "        sample_rate, data = wavfile.read(out_file)\n",
        "        len_data = len(data)\n",
        "        t = len_data / sample_rate\n",
        "        new_covid_data.append([uuid, assessment_result, out_file, sample_rate, t])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "G7raV5oJgYHj"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/covid_cut_audio\n",
        "!mkdir /content/covid_cut_audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "1Orkf3TYg048"
      },
      "outputs": [],
      "source": [
        "def createNewDataFrame(df, min_silence_len, keep_silence):\n",
        "    new_covid_data = []\n",
        "    for index, row in df.iterrows():\n",
        "        splitAudio(new_covid_data, row[\"audio_path\"], row[\"assessment_result\"], \"/content/covid_cut_audio/\", min_silence_len, keep_silence)\n",
        "    new_df = pd.DataFrame(new_covid_data, columns = ['uuid', 'assessment_result', 'audio_path', 'sample_rate', 'seconds'])\n",
        "    return new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "hcVRRwHQfHcg"
      },
      "outputs": [],
      "source": [
        "long_covid_audio_df = train_data[(train_data[\"seconds\"] > 6.13) & (train_data[\"assessment_result\"] == 1)].reset_index(drop=True)\n",
        "new_covid_df = createNewDataFrame(long_covid_audio_df, 1000, 1000)\n",
        "print(len(new_covid_df[(new_covid_df[\"seconds\"] <= 6.13)]))\n",
        "print(len(new_covid_df[(new_covid_df[\"seconds\"] > 6.13)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "kCBeb1CI8Wcl"
      },
      "outputs": [],
      "source": [
        "long_covid_audio_df2 = new_covid_df[(new_covid_df[\"seconds\"] > 6.13)].reset_index(drop=True)\n",
        "new_covid_df2 = createNewDataFrame(long_covid_audio_df2, 1000, 1000)\n",
        "print(len(new_covid_df2[(new_covid_df2[\"seconds\"] <= 6.13)]))\n",
        "print(len(new_covid_df2[(new_covid_df2[\"seconds\"] > 6.13)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "JbhtjZHZU67_"
      },
      "outputs": [],
      "source": [
        "# Loại bỏ không phải tiếng ho\n",
        "new_covid_df2 = new_covid_df2.drop([0,1]).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mYpnQbM_6ju9"
      },
      "outputs": [],
      "source": [
        "long_covid_audio_df3 = new_covid_df2[(new_covid_df2[\"seconds\"] > 6.13)].reset_index(drop=True)\n",
        "new_covid_df3 = createNewDataFrame(long_covid_audio_df3, 900, 900)\n",
        "print(len(new_covid_df3[(new_covid_df3[\"seconds\"] <= 6.13)]))\n",
        "print(len(new_covid_df3[(new_covid_df3[\"seconds\"] > 6.13)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EfHAkm198uYy"
      },
      "outputs": [],
      "source": [
        "long_covid_audio_df4 = new_covid_df3[(new_covid_df3[\"seconds\"] > 6.13)].reset_index(drop=True)\n",
        "new_covid_df4 = createNewDataFrame(long_covid_audio_df4, 800, 800)\n",
        "print(len(new_covid_df4[(new_covid_df4[\"seconds\"] <= 6.13)]))\n",
        "print(len(new_covid_df4[(new_covid_df4[\"seconds\"] > 6.13)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "_QhdLTbXX7nJ"
      },
      "outputs": [],
      "source": [
        "# xoa am thanh ho ngan qua 1.061\n",
        "new_covid_df4 = new_covid_df4.drop([45]).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wR4Zfx6I8ucU"
      },
      "outputs": [],
      "source": [
        "long_covid_audio_df5 = new_covid_df4[(new_covid_df4[\"seconds\"] > 6.13)].reset_index(drop=True)\n",
        "new_covid_df5 = createNewDataFrame(long_covid_audio_df5, 700, 700)\n",
        "print(len(new_covid_df5[(new_covid_df5[\"seconds\"] <= 6.13)]))\n",
        "print(len(new_covid_df5[(new_covid_df5[\"seconds\"] > 6.13)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ha-SRfehYtkR"
      },
      "outputs": [],
      "source": [
        "# xoa am thanh ho ngan qua 0.931\n",
        "new_covid_df5 = new_covid_df5.drop([7]).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "y3j4cAv68uhS"
      },
      "outputs": [],
      "source": [
        "long_covid_audio_df6 = new_covid_df5[(new_covid_df5[\"seconds\"] > 6.13)].reset_index(drop=True)\n",
        "new_covid_df6 = createNewDataFrame(long_covid_audio_df6, 500, 500)\n",
        "print(len(new_covid_df6[(new_covid_df6[\"seconds\"] <= 6.13)]))\n",
        "print(len(new_covid_df6[(new_covid_df6[\"seconds\"] > 6.13)]))"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2NdpyX5UZPKZ"
      },
      "outputs": [],
      "source": [
        "new_covid_df6 = new_covid_df6.drop([6, 7, 8, 9, 10, 11, 12, 13]).reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "BjgWL0UPoFvv"
      },
      "outputs": [],
      "source": [
        "not_covid_df1 = train_data[(train_data[\"seconds\"] <= 6.13) & (train_data[\"assessment_result\"] == 0)]\n",
        "covid_df0 = train_data[(train_data[\"seconds\"] <= 6.13) & (train_data[\"assessment_result\"] == 1)]\n",
        "\n",
        "covid_df1 = new_covid_df[(new_covid_df[\"seconds\"] <= 6.13)]\n",
        "covid_df2 = new_covid_df2[(new_covid_df2[\"seconds\"] <= 6.13)]\n",
        "covid_df3 = new_covid_df3[(new_covid_df3[\"seconds\"] <= 6.13)]\n",
        "covid_df4 = new_covid_df4[(new_covid_df4[\"seconds\"] <= 6.13)]\n",
        "covid_df5 = new_covid_df5[(new_covid_df5[\"seconds\"] <= 6.13)]\n",
        "covid_df6 = new_covid_df6[(new_covid_df6[\"seconds\"] <= 6.13)]\n",
        "\n",
        "final_train_data = pd.concat([not_covid_df1, covid_df0, covid_df1, covid_df2, covid_df3, covid_df4, covid_df5, covid_df6]).reset_index(drop=True)\n",
        "final_train_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2kMIfe4FZdvn"
      },
      "outputs": [],
      "source": [
        "## khong phai tieng ho hoac tieng ho nho\n",
        "## 126, 2229, 2291, 2426, 2483, 1974, 2054\n",
        "final_train_data = final_train_data.drop([126, 2229, 2291, 2426, 2483, 1974, 2054]).reset_index(drop=True)\n",
        "final_train_data = final_train_data[final_train_data[\"seconds\"] > 1.4].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AFGjmuE1cGtb"
      },
      "outputs": [],
      "source": [
        "final_train_data.assessment_result.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "FL45samUPJRP"
      },
      "source": [
        "### Remove Silent Audio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "e0bqwUB3uDa9"
      },
      "outputs": [],
      "source": [
        "!pip install aubio"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ChmtmyMjuH5r"
      },
      "outputs": [],
      "source": [
        "import sys\n",
        "import aubio\n",
        "import numpy as np\n",
        "import os\n",
        "\n",
        "def avg_fq(audio_path):\n",
        "    win_s = 2048\n",
        "    hop_s = win_s // 4\n",
        "\n",
        "    s = aubio.source(audio_path, hop_s)\n",
        "    tolerance = 0.8\n",
        "    pitch_o = aubio.pitch(\"yin\", win_s, hop_s, s.samplerate)\n",
        "    pitch_o.set_unit(\"midi\")\n",
        "    pitch_o.set_tolerance(tolerance)\n",
        "\n",
        "    pitches = []\n",
        "    confidences = []\n",
        "\n",
        "    total_frames = 0\n",
        "    while True:\n",
        "        samples, read = s()\n",
        "        pitch = pitch_o(samples)[0]\n",
        "        pitches += [pitch]\n",
        "        total_frames += read\n",
        "        if read < hop_s: break\n",
        "\n",
        "    a = np.array(pitches)\n",
        "    return a.mean()\n",
        "\n",
        "\n",
        "def hasNoSound(audio_path):\n",
        "    frq_mean = avg_fq(audio_path)\n",
        "    isSilent = False\n",
        "    if frq_mean < 1:\n",
        "        isSilent = True\n",
        "    return isSilent"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "OhRH6XBduJgA"
      },
      "outputs": [],
      "source": [
        "noSoundLST = []\n",
        "for index, row in final_train_data.iterrows():\n",
        "    if (hasNoSound(row[\"audio_path\"])):\n",
        "        noSoundLST.append(row[\"audio_path\"])"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "IALdBhlluJjc"
      },
      "outputs": [],
      "source": [
        "final_train_data = final_train_data[~final_train_data[\"audio_path\"].isin(noSoundLST)].reset_index(drop=True)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "wAjG8ZrmuJqE"
      },
      "outputs": [],
      "source": [
        "final_train_data.assessment_result.value_counts()"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "ZHhBdGzCPPko"
      },
      "source": [
        "### Data augmentation"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "KSLEOlH-KFV6"
      },
      "outputs": [],
      "source": [
        "import json\n",
        "import math\n",
        "# import noisereduce as nr\n",
        "\n",
        "import random\n",
        "\n",
        "def shiftAudio(data, sampling_rate, shift_max):\n",
        "    shift = np.random.randint(sampling_rate * shift_max)\n",
        "    shift_direction = random.choice(['right', 'both'])\n",
        "    if shift_direction == 'right':\n",
        "        shift = -shift\n",
        "    elif shift_direction == 'both':\n",
        "        direction = np.random.randint(0, 2)\n",
        "        if direction == 1:\n",
        "            shift = -shift\n",
        "    augmented_data = np.roll(data, shift)\n",
        "    # Set to silence for heading/ tailing\n",
        "    if shift > 0:\n",
        "        augmented_data[:shift] = 0\n",
        "    else:\n",
        "        augmented_data[shift:] = 0\n",
        "    return augmented_data\n",
        "\n",
        "# https://www.kaggle.com/huseinzol05/sound-augmentation-librosa\n",
        "# https://medium.com/@makcedward/data-augmentation-for-audio-76912b01fdf6\n",
        "def audio_augmentation(samples, sr):\n",
        "    y_aug = samples.copy()\n",
        "    dyn_change = np.random.uniform(low=1.5,high=3)\n",
        "    y_aug = y_aug * dyn_change\n",
        "\n",
        "    y_noise1 = samples.copy()\n",
        "    noise_amp = np.random.uniform(0.001, 0.005) * np.amax(y_noise1)\n",
        "    # noise_amp = 0.005*np.random.uniform() * np.amax(y_noise1)\n",
        "    y_noise1 = y_noise1.astype('float64') + noise_amp * np.random.normal(size=y_noise1.shape[0])\n",
        "\n",
        "    y_noise2 = samples.copy()\n",
        "    noise = np.random.randn(len(y_noise2))\n",
        "    augmented_data = y_noise2 + np.random.uniform(0.001, 0.005) * noise\n",
        "    augmented_data = augmented_data.astype(type(y_noise2[0]))\n",
        "\n",
        "    y_shift = samples.copy()\n",
        "    # timeshift_fac = 0.2 *2*(np.random.uniform()-0.5)  # up to 20% of length\n",
        "    timeshift_fac = 0.1 *2*(np.random.uniform()-0.5)\n",
        "    start = int(y_shift.shape[0] * timeshift_fac)\n",
        "    if (start > 0):\n",
        "        y_shift = np.pad(y_shift,(start,0),mode='constant')[0:y_shift.shape[0]]\n",
        "    else:\n",
        "        y_shift = np.pad(y_shift,(0,-start),mode='constant')[0:y_shift.shape[0]]\n",
        "\n",
        "    y_hpss = librosa.effects.hpss(samples.astype('float64'))\n",
        "\n",
        "    y_shift2 = samples.copy()\n",
        "    y_shift2 = shiftAudio(y_shift2, sr, 0.1)\n",
        "\n",
        "    return [y_aug, y_noise1, y_shift, y_hpss[1], y_shift2, augmented_data]\n",
        "  "
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "eP7gx7mDQSND"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/audio_augmentation\n",
        "!mkdir -p /content/audio_augmentation"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "import random\n",
        "\n",
        "def changeVolume(audio_pth, dest_pth, isIncrease):\n",
        "    delta = 0\n",
        "    if isIncrease == True:\n",
        "        delta = random.randint(5, 10)\n",
        "    else:\n",
        "        delta = random.randint(-7, -2)\n",
        "\n",
        "    song = AudioSegment.from_wav(audio_pth)\n",
        "    song_aug = song + delta\n",
        "    song_aug.export(dest_pth, \"wav\")"
      ],
      "metadata": {
        "id": "xJFHqIZrDH9X"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "rVhCCgsxKFdh"
      },
      "outputs": [],
      "source": [
        "import soundfile as sf\n",
        "\n",
        "def dataAugmentation(df, is_test):\n",
        "    new_data = []\n",
        "    for index, row in df.iterrows():\n",
        "        audio, sample_rate = librosa.load(row[\"audio_path\"], row[\"sample_rate\"])\n",
        "        new_data.append([row[\"uuid\"], row[\"assessment_result\"], row[\"audio_path\"], row[\"sample_rate\"], row[\"seconds\"], \"original\"])\n",
        "        if is_test == False:\n",
        "            audio_aug = audio_augmentation(audio, sample_rate)\n",
        "            if row[\"assessment_result\"] == 0:\n",
        "                # num_aug = random.choice([2, 3])\n",
        "                num_aug = 4\n",
        "                audio_aug = random.sample(audio_aug, num_aug)\n",
        "            for idx, y_aug in enumerate(audio_aug):\n",
        "                aug_name = \"aug\" + str(idx)\n",
        "                aud_uid = aug_name + row[\"uuid\"]\n",
        "                file_pth = \"/content/audio_augmentation/\" + aud_uid + \".wav\"\n",
        "                sf.write(file_pth, y_aug, sample_rate)\n",
        "                new_data.append([aud_uid, row[\"assessment_result\"], file_pth, row[\"sample_rate\"], row[\"seconds\"], \"augmentation\"])\n",
        "    \n",
        "            for isIncrease in [True, False]:\n",
        "                aud_uid = \"increase\" + str(isIncrease) + row[\"uuid\"]\n",
        "                file_pth = \"/content/audio_augmentation/\" + aud_uid + \".wav\"\n",
        "                changeVolume(row[\"audio_path\"], file_pth, isIncrease)\n",
        "                new_data.append([aud_uid, row[\"assessment_result\"], file_pth, row[\"sample_rate\"], row[\"seconds\"], \"augmentation\"])\n",
        "    \n",
        "    new_df = pd.DataFrame(new_data, columns = ['uuid', 'assessment_result', 'audio_path', 'sample_rate', 'seconds', 'type_data'])\n",
        "    return new_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "zxF16CUfKFg7"
      },
      "outputs": [],
      "source": [
        "final_aug_data = dataAugmentation(final_train_data, False)\n",
        "final_aug_data"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "Xg21UMvkYmVT"
      },
      "outputs": [],
      "source": [
        "final_aug_data[\"assessment_result\"].value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EzFDnLBle_nD"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/final_audio_data\n",
        "!mkdir -p /content/final_audio_data\n",
        "for index, row in final_aug_data.iterrows():\n",
        "    src = row[\"audio_path\"]\n",
        "    dst = \"/content/final_audio_data/\"+row[\"uuid\"]+\".wav\"\n",
        "    copyfile(src, dst)\n",
        "\n",
        "final_aug_data['audio_path'] = final_aug_data['audio_path'].apply(lambda x: \"/content/final_audio_data/\"+os.path.basename(x))\n",
        "final_aug_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "j_aoLsbmgxah"
      },
      "source": [
        "### Extract MFCC Features with Jlibrosa"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "vuUFsnj6fUf_"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/train255/kambria-challenge"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "ROX2JYbNfUjU"
      },
      "outputs": [],
      "source": [
        "!rm -rf /content/mfcc_features\n",
        "!mkdir -p /content/mfcc_features\n",
        "%cd /content/kambria-challenge/generateMFCC/\n",
        "!javac -source 1.7 -target 1.7 -d bin -cp lib/jlibrosa-1.1.8-SNAPSHOT-jar-with-dependencies.jar src/com/example/Main.java\n",
        "!java -cp lib/jlibrosa-1.1.8-SNAPSHOT-jar-with-dependencies.jar:bin com.example.Main /content/final_audio_data /content/mfcc_features 16000 120"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "sy9sSlsytvtP"
      },
      "outputs": [],
      "source": [
        "target_names = ['not_covid',  'covid']\n",
        "num_rows = 120\n",
        "num_columns = 192\n",
        "num_channels = 1\n",
        "\n",
        "n_fft = 4096\n",
        "hop_length = 512\n",
        "n_mels = 512"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "4wVZf0m6y4lM"
      },
      "outputs": [],
      "source": [
        "def add_pad_len(x):\n",
        "    if x.shape[1] <= num_columns:\n",
        "        pad_width = num_columns - x.shape[1]\n",
        "        x = np.pad(x, pad_width=((0,0),(0,pad_width)), mode='constant')\n",
        "    return x"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "fJ94sTdMhDvO"
      },
      "outputs": [],
      "source": [
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "def readFeatures(uuid, features_dir):\n",
        "    txt_pth = features_dir + uuid + \".txt\"\n",
        "    mfcc_txt = Path(txt_pth).read_text()\n",
        "    cols = []\n",
        "    for cols_txt in mfcc_txt.split(\"n\"):\n",
        "        if cols_txt != \"\":\n",
        "            rows_str = cols_txt.split(\",\")\n",
        "            rows = []\n",
        "            for row in rows_str:\n",
        "                if row != \"\":\n",
        "                    rows.append(float(row))\n",
        "            cols.append(rows)\n",
        "    features = np.array(cols, dtype=np.float)\n",
        "    if (features.shape[0] > 192 or features.shape[1] > 192):\n",
        "        print(features.shape)\n",
        "        print(uuid)\n",
        "    features = add_pad_len(features)\n",
        "    return features"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "AVQYfjLFhDyd"
      },
      "outputs": [],
      "source": [
        "final_aug_data[\"feature\"] = final_aug_data[\"uuid\"].apply(readFeatures, features_dir=\"/content/mfcc_features/\")\n",
        "final_aug_data.to_csv(\"/content/drive/MyDrive/ML/covid_cough_detection/final_aug_data.csv\", index=False)\n",
        "final_aug_data"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "n0asT7mW0dYw"
      },
      "source": [
        "### Training"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "bUVDD3JPte7A"
      },
      "outputs": [],
      "source": [
        "from sklearn.model_selection import StratifiedKFold\n",
        "kfold = StratifiedKFold(n_splits=5, shuffle=True, random_state=42)\n",
        "\n",
        "tmp_df = final_aug_data[final_aug_data[\"type_data\"] == \"original\"].reset_index(drop=True)\n",
        "tmp_df = tmp_df[[\"audio_path\", \"assessment_result\"]]\n",
        "fold = 0\n",
        "for train_ix, test_ix in kfold.split(tmp_df, tmp_df[\"assessment_result\"]):\n",
        "    tmp_df.loc[test_ix, [\"fold\"+str(fold)]] = int(fold)\n",
        "    fold += 1\n",
        "\n",
        "tmp_df.drop(columns=[\"assessment_result\"], inplace=True)\n",
        "tmp_df.fold0.value_counts()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mMpckpjy1FeI"
      },
      "outputs": [],
      "source": [
        "final_df = pd.concat([final_aug_data, tmp_df], axis=1)\n",
        "final_df"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "EA_7OLCG0Dxo"
      },
      "outputs": [],
      "source": [
        "def create_cnn():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(16, (7,7), input_shape=(num_rows, num_columns, num_channels), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(32, (3,3), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64, (3,3), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(128, (3,3), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(256, (3,3), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (1,1), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "5Q2-6cGb0K5C"
      },
      "outputs": [],
      "source": [
        "class DataGenerator(Sequence):\n",
        "    def __init__(self,\n",
        "                _X,\n",
        "                batch_size=32,\n",
        "                n_channels=1,\n",
        "                n_columns=470,\n",
        "                n_rows=120,\n",
        "                shuffle=True):\n",
        "        self.batch_size = batch_size\n",
        "        self.X = _X\n",
        "        self.n_channels = n_channels\n",
        "        self.n_columns = n_columns\n",
        "        self.n_rows = n_rows\n",
        "        self.shuffle = shuffle\n",
        "        self.img_indexes = np.arange(len(self.X))\n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.img_indexes) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        # Find list of IDs\n",
        "        list_IDs_temps = [self.img_indexes[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temps)\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.X))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temps):\n",
        "        X = np.empty((self.batch_size, self.n_rows, self.n_columns))\n",
        "        # X = np.empty((self.batch_size, self.n_rows, self.n_columns, self.n_channels))\n",
        "        y = np.empty((self.batch_size), dtype=int)\n",
        "        for i, ID in enumerate(list_IDs_temps):\n",
        "            # x_features = self.X.iloc[ID][\"feature\"].tolist()\n",
        "            x_features = self.X.iloc[ID][\"feature\"]\n",
        "            label = self.X.iloc[ID][\"assessment_result\"]\n",
        "            # print(np.array(x_features).shape)\n",
        "            # X[i] = np.array(x_features)\n",
        "            X[i] = x_features\n",
        "            y[i] = label\n",
        "        X = X.reshape(X.shape[0], self.n_rows, self.n_columns, self.n_channels)\n",
        "        # y_convert = keras.utils.to_categorical(y, num_classes=self.n_classes)\n",
        "        return X, y"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "u70D_YcM0SJu"
      },
      "outputs": [],
      "source": [
        "params = dict(\n",
        "    batch_size=16,\n",
        "    n_rows=num_rows,\n",
        "    n_columns=num_columns,\n",
        "    n_channels=num_channels,\n",
        ")\n",
        "params_train = dict(\n",
        "    shuffle=True,\n",
        "    **params\n",
        ")\n",
        "params_valid = dict(\n",
        "    shuffle=False,\n",
        "    **params\n",
        ")"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "0wcWCLxs0Uzs"
      },
      "outputs": [],
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_his(history):\n",
        "    plt.figure(1, figsize = (15,8))\n",
        "    plt.subplot(221)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'valid'])\n",
        "    plt.subplot(222)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'valid'])\n",
        "    plt.show()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "cLuWo8GN0Y3j"
      },
      "outputs": [],
      "source": [
        "def train_model(model, train_gen, val_gen, fold):\n",
        "    checkpoint_model_path = \"/content/cnn_\"+str(fold)+\".hdf5\"\n",
        "    metric = \"val_loss\"\n",
        "    print(\"METRIC:\", metric)\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "    num_epochs = 100\n",
        "\n",
        "    checkpointer = ModelCheckpoint(\n",
        "        filepath=checkpoint_model_path,\n",
        "        monitor=metric, verbose=1, save_best_only=True)\n",
        "    es_callback = EarlyStopping(monitor=metric, patience=10, verbose=1)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor=metric, factor=0.3, patience=1, verbose=1, min_delta=0.0001, cooldown=1, min_lr=0.00001)\n",
        "\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        epochs=num_epochs,\n",
        "        validation_data=val_gen,\n",
        "        callbacks=[checkpointer,es_callback,reduce_lr],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    plot_his(history)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "n6RN_sJTp1xH"
      },
      "outputs": [],
      "source": [
        "for fold in range(5):\n",
        "    X_valid = final_df[final_df[\"fold\"+str(fold)] == fold].reset_index(drop=True)\n",
        "    X_train = final_df[final_df[\"fold\"+str(fold)] != fold].reset_index(drop=True)\n",
        "    train_generator = DataGenerator(X_train, **params_train)\n",
        "    valid_generator = DataGenerator(X_valid, **params_valid)\n",
        "    cnn_model = create_cnn()\n",
        "    train_model(cnn_model, train_generator, valid_generator, fold)"
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Verify train test data"
      ],
      "metadata": {
        "id": "8ee2EysIHYwR"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "infer_df = final_df[final_df[\"type_data\"] == \"original\"].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "4LM6c79oHcBT"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = dict(\n",
        "    batch_size=1,\n",
        "    n_rows=num_rows,\n",
        "    n_columns=num_columns,\n",
        "    n_channels=num_channels,\n",
        ")\n",
        "params_valid = dict(\n",
        "    shuffle=False,\n",
        "    **params\n",
        ")\n",
        "full_gen = DataGenerator(infer_df, **params_valid)\n",
        "\n",
        "pred_models = []\n",
        "for fold in range(5):\n",
        "    # if fold == 4:\n",
        "        checkpoint_model_path = \"/content/cnn_\"+str(fold)+\".hdf5\"\n",
        "        cnn_model = create_cnn(\"mobilenet\")\n",
        "        cnn_model.load_weights(checkpoint_model_path)\n",
        "        y_preds = cnn_model.predict(full_gen)\n",
        "        predictions = [p[0] for p in y_preds]\n",
        "        pred_models.append(predictions)"
      ],
      "metadata": {
        "id": "E_sw-GsnIAvh"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "infer_df[\"pred\"] = np.average(pred_models, axis=0)\n",
        "\n",
        "from sklearn.metrics import classification_report\n",
        "\n",
        "print(classification_report(infer_df[\"assessment_result\"], np.round(infer_df[\"pred\"]), target_names=[\"not_covid\", \"covid\"]))"
      ],
      "metadata": {
        "id": "SQUgfwFmIMun"
      },
      "execution_count": null,
      "outputs": []
    }
  ],
  "metadata": {
    "accelerator": "GPU",
    "colab": {
      "collapsed_sections": [],
      "name": "Kambria Hackathon II Final - Covid19 Detection.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}