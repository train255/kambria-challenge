{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "Kambria Hackathon II Final - Cough Detection.ipynb",
      "provenance": [],
      "collapsed_sections": [],
      "machine_shape": "hm"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "mdYr-weusSCy"
      },
      "outputs": [],
      "source": [
        "%cd /content\n",
        "!wget https://github.com/karoldvl/ESC-50/archive/master.zip"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "!mkdir -p /content/speech_commands\n",
        "%cd /content/speech_commands\n",
        "!wget http://download.tensorflow.org/data/speech_commands_v0.02.tar.gz\n",
        "!tar -xzf speech_commands_v0.02.tar.gz"
      ],
      "metadata": {
        "id": "2QSjKAra0DtJ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -f /content/esc_audio_16k\n",
        "!mkdir -p /content/esc_audio_16k\n",
        "%cd /content/ESC-50-master/audio\n",
        "!for i in *.wav; do name=`echo \"${i%.*}\"` ; ffmpeg -y -i \"${name}.wav\" -ar 16000 -ac 1 \"/content/esc_audio_16k/${name}.wav\"; done"
      ],
      "metadata": {
        "id": "so8V2P0CO6_w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "import os\n",
        "from sklearn.model_selection import train_test_split\n",
        "from tensorflow import keras\n",
        "import tensorflow as tf\n",
        "\n",
        "from tensorflow.keras.models import Model, Sequential\n",
        "from tensorflow.keras.layers import BatchNormalization, Dropout, Conv2D, Dense, GlobalAveragePooling2D, concatenate\n",
        "from tensorflow.keras.callbacks import ModelCheckpoint, EarlyStopping, ReduceLROnPlateau\n",
        "from tensorflow.keras.optimizers import Adam\n",
        "from tensorflow.keras import optimizers\n",
        "from tensorflow.keras.utils import plot_model, Sequence\n",
        "\n",
        "from sklearn.metrics import classification_report, confusion_matrix, accuracy_score\n",
        "\n",
        "import matplotlib\n",
        "import matplotlib.pyplot as plt\n",
        "from shutil import copyfile"
      ],
      "metadata": {
        "id": "G9mnAX0DkIuN"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!git clone https://github.com/train255/kambria-challenge\n",
        "%cd /content/kambria-challenge/generateMFCC/\n",
        "!javac -source 1.7 -target 1.7 -d bin -cp lib/jlibrosa-1.1.8-SNAPSHOT-jar-with-dependencies.jar src/com/example/Main.java"
      ],
      "metadata": {
        "id": "VHQ2Or7g6ATt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!pip install pydub"
      ],
      "metadata": {
        "id": "H1tDzX9mrEgI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Load data"
      ],
      "metadata": {
        "id": "kyLxy7e66JgZ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "meta_df = pd.read_csv(\"/content/ESC-50-master/meta/esc50.csv\")\n",
        "meta_df[\"audio_path\"] = meta_df[\"filename\"].apply(lambda x: \"/content/esc_audio_16k/\"+x)\n",
        "meta_df[\"uuid\"] = meta_df[\"filename\"].apply(lambda x: x.split(\".wav\")[0])\n",
        "meta_df"
      ],
      "metadata": {
        "id": "SYh_dZX-klm1"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "speech_validation_df = pd.read_csv(\"/content/speech_commands/validation_list.txt\", header=None).reset_index(drop=True)\n",
        "speech_validation_df = speech_validation_df.rename(columns = {0: 'path'})\n",
        "speech_validation_df"
      ],
      "metadata": {
        "id": "L2cxMXjg5CsG"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "speech_testing_df = pd.read_csv(\"/content/speech_commands/testing_list.txt\", header=None).reset_index(drop=True)\n",
        "speech_testing_df = speech_testing_df.rename(columns = {0: 'path'})\n",
        "speech_testing_df"
      ],
      "metadata": {
        "id": "gse4kYaB62VS"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "speech_df = pd.concat([speech_validation_df, speech_testing_df])\n",
        "speech_df = speech_df.sort_values(\"path\").reset_index(drop=True)\n",
        "speech_df[\"category\"] = speech_df[\"path\"].apply(lambda x: os.path.dirname(x))\n",
        "speech_df[\"uuid\"] = speech_df[\"path\"].apply(lambda x: os.path.basename(x).split(\".wav\")[0])\n",
        "speech_df[\"audio_path\"] = speech_df[\"path\"].apply(lambda x: \"/content/speech_commands/\"+x)\n",
        "speech_df"
      ],
      "metadata": {
        "id": "Qz5T_QG7NPl0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_meta_df = pd.read_csv(\"/content/aicv115m_final_public_train/public_train_metadata.csv\")\n",
        "train_audio_dir = \"/content/final_public_train/\"\n",
        "train_meta_df[\"audio_path\"] = train_meta_df[\"uuid\"].apply(lambda x: train_audio_dir + x + \".wav\")\n",
        "train_meta_df.drop(train_meta_df[train_meta_df['uuid'] == \"23ccaa28-8cb8-43e4-9e59-112fa4dc6559\"].index, inplace = True)\n",
        "idx_lst = [169, 1063, 2064, 2297, 2512, 2723, 2832, 3143, 3600, 3774, 3820, 4191, 4378]\n",
        "df_covid = train_meta_df.iloc[idx_lst][[\"uuid\",\"assessment_result\", \"audio_path\"]].reset_index(drop=True)\n",
        "train_nonote_df = train_meta_df[train_meta_df.audio_noise_note.isnull()].reset_index(drop=True)\n",
        "train_nonote_df = train_nonote_df[[\"uuid\",\"assessment_result\", \"audio_path\"]]\n",
        "train_data = pd.concat([train_nonote_df, df_covid]).reset_index(drop=True)\n",
        "train_data = train_data[[\"uuid\",\"assessment_result\", \"audio_path\"]]"
      ],
      "metadata": {
        "id": "MdrcgWDF08Rr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "# Get duration and sample rate\n",
        "import scipy\n",
        "from scipy.io import wavfile\n",
        "\n",
        "def getRateAndDuration(_df):\n",
        "    sample_rate_lst = []\n",
        "    seconds_lst = []\n",
        "    for index, row in _df.iterrows():\n",
        "        sample_rate, data = wavfile.read(row[\"audio_path\"])\n",
        "        sample_rate_lst.append(sample_rate)\n",
        "        len_data = len(data)  # holds length of the numpy array\n",
        "        t = len_data / sample_rate  # returns duration but in floats\n",
        "        seconds_lst.append(t)\n",
        "    _df[\"sample_rate\"] = sample_rate_lst\n",
        "    _df[\"seconds\"] = seconds_lst\n",
        "    return _df"
      ],
      "metadata": {
        "id": "CqfDWoWyT7o0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = getRateAndDuration(train_data)\n",
        "cough_aicovid_df = train_data[(train_data[\"seconds\"] <= 6.13)].reset_index(drop=True)\n",
        "cough_aicovid_df[\"assessment_result\"] = [1] * len(cough_aicovid_df)"
      ],
      "metadata": {
        "id": "CFNLrkd6T_Iq"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "background_noises = [\"doing_the_dishes\", \"dude_miaowing\", \"exercise_bike\",\n",
        "                             \"pink_noise\", \"running_tap\", \"white_noise\"]\n",
        "bg_data = []\n",
        "for i in background_noises:\n",
        "    uuid = i\n",
        "    aug_pth = \"/content/speech_commands/_background_noise_/\" + uuid + \".wav\"\n",
        "    bg_data.append([uuid, aug_pth])\n",
        "\n",
        "bg_noise_df = pd.DataFrame(bg_data, columns = ['uuid', 'audio_path'])\n",
        "bg_noise_df"
      ],
      "metadata": {
        "id": "wL4nU-D-d_JC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Positive Data"
      ],
      "metadata": {
        "id": "GC5ltiha6Cy9"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "from pydub import AudioSegment\n",
        "import random\n",
        "import os\n",
        "\n",
        "def mixAudio(cough_path, noise_path, dst_dir):\n",
        "    cough_name = os.path.basename(cough_path)\n",
        "    noise_name = os.path.basename(noise_path)\n",
        "    uuid = cough_name.split(\".wav\")[0]+noise_name.split(\".wav\")[0]\n",
        "    new_name = uuid+\".wav\"\n",
        "    sound1 = AudioSegment.from_file(cough_path, format=\"wav\")\n",
        "    sound2 = AudioSegment.from_file(noise_path, format=\"wav\")\n",
        "\n",
        "    # sound1 6 dB louder\n",
        "    sound2_aug = sound2 - random.randint(8, 12)\n",
        "\n",
        "    # sound1, with sound2 appended (use louder instead of sound1 to append the louder version)\n",
        "    combined = sound1.overlay(sound2_aug)\n",
        "    pth = dst_dir+new_name\n",
        "    # simple export\n",
        "    combined.export(pth, format=\"wav\")\n",
        "    return pth, uuid\n",
        "\n",
        "def mixBackground(_df, aug_df, label, dst_dir):\n",
        "    mix_data = []\n",
        "    for index, row in _df.iterrows():\n",
        "        for index2, row_aug in aug_df.iterrows():\n",
        "            aug_pth, uuid = mixAudio(row[\"audio_path\"], row_aug[\"audio_path\"], dst_dir)\n",
        "            mix_data.append([uuid, aug_pth, label])\n",
        "    return pd.DataFrame(mix_data, columns = ['uuid', 'audio_path', 'assessment_result'])"
      ],
      "metadata": {
        "id": "OhDqrkO7rXU_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def addLabel(_df, label):\n",
        "    _df[\"assessment_result\"] = [label] * len(_df)\n",
        "    return _df[[\"uuid\", \"audio_path\", \"assessment_result\"]].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "K7JzuX1NGp2I"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cough_esc_df_train = meta_df[(meta_df[\"fold\"] < 4) & (meta_df[\"category\"] == \"coughing\")].reset_index(drop=True)\n",
        "cough_esc_df_valid = meta_df[(meta_df[\"fold\"] == 4) & (meta_df[\"category\"] == \"coughing\")].reset_index(drop=True)\n",
        "cough_esc_df_test = meta_df[(meta_df[\"fold\"] == 5) & (meta_df[\"category\"] == \"coughing\")].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "73gdiAe6NJRj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "wind_bg_df = meta_df[(meta_df[\"category\"]==\"wind\") & (meta_df[\"src_file\"] <= 47709)]\n",
        "rain_bg_df = meta_df[(meta_df[\"category\"]==\"rain\") & (meta_df[\"src_file\"] <= 21189)]\n",
        "clock_tick_bg_df = meta_df[(meta_df[\"category\"]==\"clock_tick\") & (meta_df[\"src_file\"] <= 21935)]\n",
        "footsteps_bg_df = meta_df[(meta_df[\"category\"]==\"footsteps\") & (meta_df[\"src_file\"] <= 51149)]\n",
        "esc_bg_df = pd.concat([wind_bg_df, rain_bg_df, clock_tick_bg_df, footsteps_bg_df])\n",
        "esc_bg_idx = esc_bg_df.index.tolist()\n",
        "cough_esc_data_background = esc_bg_df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "YvEhsveDAWSQ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf \"/content/cough_aug/\"\n",
        "!mkdir -p \"/content/cough_aug/\"\n",
        "cough_mix_esc_df = mixBackground(cough_esc_df_train, cough_esc_data_background, 1, \"/content/cough_aug/\")"
      ],
      "metadata": {
        "id": "Mh37lJyGrcPl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "go_bg_df = speech_df[(speech_df[\"category\"]==\"go\") & (speech_df.index <= 5624)]\n",
        "up_bg_df = speech_df[(speech_df[\"category\"]==\"up\") & (speech_df.index <= 17891)]\n",
        "down_bg_df = speech_df[(speech_df[\"category\"]==\"down\") & (speech_df.index <= 1897)]\n",
        "right_bg_df = speech_df[(speech_df[\"category\"]==\"right\") & (speech_df.index <= 12508)]\n",
        "left_bg_df = speech_df[(speech_df[\"category\"]==\"left\") & (speech_df.index <= 7495)]\n",
        "yes_bg_df = speech_df[(speech_df[\"category\"]==\"yes\") & (speech_df.index <= 19369)]\n",
        "no_bg_df = speech_df[(speech_df[\"category\"]==\"no\") & (speech_df.index <= 9413)]\n",
        "speech_bg_df = pd.concat([go_bg_df, up_bg_df, down_bg_df, right_bg_df, left_bg_df, yes_bg_df, no_bg_df])\n",
        "speech_bg_idx = speech_bg_df.index.tolist()\n",
        "cough_speech_data_background = speech_bg_df.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "GJoi4Astsjqj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf \"/content/cough_aug2/\"\n",
        "!mkdir -p \"/content/cough_aug2/\"\n",
        "cough_mix_speech_df = mixBackground(cough_esc_df_train, cough_speech_data_background, 1, \"/content/cough_aug2/\")"
      ],
      "metadata": {
        "id": "UbFtZNpVNx5w"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cough_aicovid_df_train, cough_aicovid_df_valid, cough_aicovid_df_test = np.split(cough_aicovid_df.sample(frac=1, random_state=42), [int(.8*len(cough_aicovid_df)), int(.9*len(cough_aicovid_df))])\n",
        "cough_aicovid_df_train = cough_aicovid_df_train[[\"uuid\", \"audio_path\", \"assessment_result\"]].reset_index(drop=True)\n",
        "cough_aicovid_df_valid = cough_aicovid_df_valid[[\"uuid\", \"audio_path\", \"assessment_result\"]].reset_index(drop=True)\n",
        "cough_aicovid_df_test = cough_aicovid_df_test[[\"uuid\", \"audio_path\", \"assessment_result\"]].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "v4UmIM8X2h3c"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf \"/content/cough_aug3/\"\n",
        "!mkdir -p \"/content/cough_aug3/\"\n",
        "cough_ai_mix_esc_df = mixBackground(cough_aicovid_df_train, cough_esc_data_background, 1, \"/content/cough_aug3/\")"
      ],
      "metadata": {
        "id": "pi28bc9jUgPr"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf \"/content/cough_aug4/\"\n",
        "!mkdir -p \"/content/cough_aug4/\"\n",
        "cough_ai_mix_speech_df = mixBackground(cough_aicovid_df_train, cough_speech_data_background, 1, \"/content/cough_aug4/\")"
      ],
      "metadata": {
        "id": "7FJZvaKUVFHg"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf \"/content/cough_aug5/\"\n",
        "!mkdir -p \"/content/cough_aug5/\"\n",
        "cough_mix_bg_noise_df = mixBackground(cough_esc_df_train, bg_noise_df, 1, \"/content/cough_aug5/\")"
      ],
      "metadata": {
        "id": "03oEtSiagpB3"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf \"/content/cough_aug6/\"\n",
        "!mkdir -p \"/content/cough_aug6/\"\n",
        "cough_ai_mix_bg_noise_df = mixBackground(cough_aicovid_df_train, bg_noise_df, 1, \"/content/cough_aug6/\")"
      ],
      "metadata": {
        "id": "zQUaQ3_jgxSC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "cough_esc_df_train = addLabel(cough_esc_df_train, 1)\n",
        "cough_esc_df_valid = addLabel(cough_esc_df_valid, 1)\n",
        "cough_esc_df_test = addLabel(cough_esc_df_test, 1)"
      ],
      "metadata": {
        "id": "La_YbjMqkwdI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_df_train = pd.concat([cough_esc_df_train, cough_mix_esc_df, cough_mix_speech_df,\n",
        "                               cough_aicovid_df_train, cough_ai_mix_esc_df, cough_ai_mix_speech_df,\n",
        "                               cough_mix_bg_noise_df, cough_ai_mix_bg_noise_df]).reset_index(drop=True)\n",
        "\n",
        "positive_df_valid = pd.concat([cough_esc_df_valid, cough_aicovid_df_valid]).reset_index(drop=True)\n",
        "positive_df_test = pd.concat([cough_esc_df_test, cough_aicovid_df_test]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "w2vYsAdvyjaD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(positive_df_train))\n",
        "print(len(positive_df_valid))\n",
        "print(len(positive_df_test))"
      ],
      "metadata": {
        "id": "Ws9xBdr01KyD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "#### Negative Data"
      ],
      "metadata": {
        "id": "1mFKWV5DiHjt"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "no_cough_esc_df = meta_df[(~meta_df.index.isin(esc_bg_idx)) & (meta_df[\"category\"] != \"coughing\")].reset_index(drop=True)\n",
        "no_cough_esc_df_train = no_cough_esc_df[no_cough_esc_df[\"fold\"] < 4].reset_index(drop=True)\n",
        "no_cough_esc_df_valid = no_cough_esc_df[no_cough_esc_df[\"fold\"] == 4].reset_index(drop=True)\n",
        "no_cough_esc_df_test = no_cough_esc_df[no_cough_esc_df[\"fold\"] == 5].reset_index(drop=True)"
      ],
      "metadata": {
        "id": "bBhTHDKLMxTB"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_cough_speech_df = speech_df[~speech_df.index.isin(speech_bg_idx)].reset_index(drop=True)\n",
        "X_train, speech_other_df_test = train_test_split(no_cough_speech_df, test_size=0.1, random_state=42)\n",
        "speech_other_df_train, speech_other_df_valid = train_test_split(X_train, test_size=0.11, random_state=42)\n",
        "speech_other_df_train = speech_other_df_train.reset_index(drop=True)\n",
        "speech_other_df_valid = speech_other_df_valid.reset_index(drop=True)\n",
        "speech_other_df_test = speech_other_df_test.reset_index(drop=True)"
      ],
      "metadata": {
        "id": "6EETgL9OiieP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf \"/content/no_cough_aug1/\"\n",
        "!mkdir -p \"/content/no_cough_aug1/\"\n",
        "no_cough_esc_mix_bg_noise_df = mixBackground(no_cough_esc_df_train, bg_noise_df, 0, \"/content/no_cough_aug1/\")"
      ],
      "metadata": {
        "id": "HIoYtnZxizb_"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def mixRandomBackground(_df, aug_df, label, dst_dir, n):\n",
        "    mix_data = []\n",
        "    for index, row in _df.iterrows():\n",
        "        aug_rand = aug_df.sample(n=n).reset_index(drop=True)\n",
        "        for index2, row_aug in aug_rand.iterrows():\n",
        "            aug_pth, uuid = mixAudio(row[\"audio_path\"], row_aug[\"audio_path\"], dst_dir)\n",
        "            mix_data.append([uuid, aug_pth, label])\n",
        "    return pd.DataFrame(mix_data, columns = ['uuid', 'audio_path', 'assessment_result'])"
      ],
      "metadata": {
        "id": "FBkOdMRAswAD"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf \"/content/no_cough_aug2/\"\n",
        "!mkdir -p \"/content/no_cough_aug2/\"\n",
        "speech_mix_bg_noise_df = mixRandomBackground(speech_other_df_train, bg_noise_df, 0, \"/content/no_cough_aug2/\", 1)"
      ],
      "metadata": {
        "id": "nAynU80wktPI"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "no_cough_esc_df_train = addLabel(no_cough_esc_df_train, 0)\n",
        "speech_other_df_train = addLabel(speech_other_df_train, 0)\n",
        "no_cough_esc_df_valid = addLabel(no_cough_esc_df_valid, 0)\n",
        "no_cough_esc_df_test = addLabel(no_cough_esc_df_test, 0)\n",
        "speech_other_df_valid = addLabel(speech_other_df_valid, 0)\n",
        "speech_other_df_test = addLabel(speech_other_df_test, 0)"
      ],
      "metadata": {
        "id": "Qtq45ClektZc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_df_train = pd.concat([no_cough_esc_df_train, speech_other_df_train,\n",
        "                               no_cough_esc_mix_bg_noise_df, speech_mix_bg_noise_df]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "is89Tehty1oz"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_df_valid = pd.concat([no_cough_esc_df_valid, speech_other_df_valid]).reset_index(drop=True)\n",
        "negative_df_test = pd.concat([no_cough_esc_df_test, speech_other_df_test]).reset_index(drop=True)"
      ],
      "metadata": {
        "id": "DCS11w-e2v1A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(len(negative_df_train))\n",
        "print(len(negative_df_valid))\n",
        "print(len(negative_df_test))"
      ],
      "metadata": {
        "id": "bqRf98qKLZKZ"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Create features"
      ],
      "metadata": {
        "id": "2WovCSqRM1LQ"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "num_rows = 120\n",
        "num_columns = 192\n",
        "num_channels = 1\n",
        "\n",
        "n_fft = 4096\n",
        "hop_length = 512\n",
        "n_mels = 512\n",
        "\n",
        "from pathlib import Path\n",
        "import re\n",
        "\n",
        "def add_pad_len(x):\n",
        "    if x.shape[1] <= num_columns:\n",
        "        pad_width = num_columns - x.shape[1]\n",
        "        x = np.pad(x, pad_width=((0,0),(0,pad_width)), mode='constant')\n",
        "    return x\n",
        "\n",
        "def readFeatures(uuid, features_dir):\n",
        "    txt_pth = features_dir + uuid + \".txt\"\n",
        "    mfcc_txt = Path(txt_pth).read_text()\n",
        "    cols = []\n",
        "    for cols_txt in mfcc_txt.split(\"n\"):\n",
        "        if cols_txt != \"\":\n",
        "            rows_str = cols_txt.split(\",\")\n",
        "            rows = []\n",
        "            for row in rows_str:\n",
        "                # if row != \"\" and isFloatFormat(row):\n",
        "                if row != \"\":\n",
        "                    rows.append(float(row))\n",
        "            cols.append(rows)\n",
        "    features = np.array(cols, dtype=np.float)\n",
        "    if (features.shape[0] > 192 or features.shape[1] > 192):\n",
        "        print(features.shape)\n",
        "        print(uuid)\n",
        "    features = add_pad_len(features)\n",
        "    return features"
      ],
      "metadata": {
        "id": "tBe8rQJQ2UeR"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/cough_data\n",
        "!mkdir -p /content/cough_data\n",
        "for index, row in positive_df_train.iterrows():\n",
        "    src = row[\"audio_path\"]\n",
        "    dst = \"/content/cough_data/\"+row[\"uuid\"]+\".wav\"\n",
        "    copyfile(src, dst)\n",
        "positive_df_train['audio_path'] = positive_df_train['audio_path'].apply(lambda x: \"/content/cough_data/\"+os.path.basename(x))"
      ],
      "metadata": {
        "id": "9iCBL9gRLZOK"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/cough_features\n",
        "!mkdir -p /content/cough_features\n",
        "%cd /content/kambria-challenge/generateMFCC/\n",
        "!java -cp lib/jlibrosa-1.1.8-SNAPSHOT-jar-with-dependencies.jar:bin com.example.Main /content/cough_data /content/cough_features 16000 120"
      ],
      "metadata": {
        "id": "_9H9zMqX3Lhd"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_df_train[\"feature\"] = positive_df_train[\"uuid\"].apply(readFeatures, features_dir=\"/content/cough_features/\")"
      ],
      "metadata": {
        "id": "rzoQE9gc3UpA"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/no_cough_data\n",
        "!mkdir -p /content/no_cough_data\n",
        "for index, row in negative_df_train.iterrows():\n",
        "    src = row[\"audio_path\"]\n",
        "    dst = \"/content/no_cough_data/\"+row[\"uuid\"]+\".wav\"\n",
        "    copyfile(src, dst)\n",
        "negative_df_train['audio_path'] = negative_df_train['audio_path'].apply(lambda x: \"/content/no_cough_data/\"+os.path.basename(x))"
      ],
      "metadata": {
        "id": "iyUHOYxcQh46"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/no_cough_features\n",
        "!mkdir -p /content/no_cough_features\n",
        "%cd /content/kambria-challenge/generateMFCC/\n",
        "!java -cp lib/jlibrosa-1.1.8-SNAPSHOT-jar-with-dependencies.jar:bin com.example.Main /content/no_cough_data /content/no_cough_features 16000 120"
      ],
      "metadata": {
        "id": "JDlzn4YTQq6v"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_df_train[\"feature\"] = negative_df_train[\"uuid\"].apply(readFeatures, features_dir=\"/content/no_cough_features/\")"
      ],
      "metadata": {
        "id": "4zl6kb2aJ4Cm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "%cd /content\n",
        "!unzip -q /content/drive/MyDrive/ML/cough_recognition/cough_data.zip -d ./\n",
        "!unzip -q /content/drive/MyDrive/ML/cough_recognition/cough_features.zip -d ./\n",
        "!unzip -q /content/drive/MyDrive/ML/cough_recognition/no_cough_data.zip -d ./\n",
        "!unzip -q /content/drive/MyDrive/ML/cough_recognition/no_cough_features.zip -d ./"
      ],
      "metadata": {
        "id": "T2JfJwrBKL69"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_aug_data = pd.concat([positive_df_train, negative_df_train])"
      ],
      "metadata": {
        "id": "_d94cr-R3Y9o"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/cough_data_valid\n",
        "!mkdir -p /content/cough_data_valid\n",
        "for index, row in positive_df_valid.iterrows():\n",
        "    src = row[\"audio_path\"]\n",
        "    dst = \"/content/cough_data_valid/\"+row[\"uuid\"]+\".wav\"\n",
        "    copyfile(src, dst)\n",
        "positive_df_valid['audio_path'] = positive_df_valid['audio_path'].apply(lambda x: \"/content/cough_data_valid/\"+os.path.basename(x))"
      ],
      "metadata": {
        "id": "5Y2cOchMSfB5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/cough_valid_features\n",
        "!mkdir -p /content/cough_valid_features\n",
        "%cd /content/kambria-challenge/generateMFCC/\n",
        "!java -cp lib/jlibrosa-1.1.8-SNAPSHOT-jar-with-dependencies.jar:bin com.example.Main /content/cough_data_valid /content/cough_valid_features 16000 120"
      ],
      "metadata": {
        "id": "LysB6oTVTzuP"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "positive_df_valid[\"feature\"] = positive_df_valid[\"uuid\"].apply(readFeatures, features_dir=\"/content/cough_valid_features/\")"
      ],
      "metadata": {
        "id": "mKtqo8l0TzxW"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/no_cough_data_valid\n",
        "!mkdir -p /content/no_cough_data_valid\n",
        "for index, row in negative_df_valid.iterrows():\n",
        "    src = row[\"audio_path\"]\n",
        "    dst = \"/content/no_cough_data_valid/\"+row[\"uuid\"]+\".wav\"\n",
        "    copyfile(src, dst)\n",
        "negative_df_valid['audio_path'] = negative_df_valid['audio_path'].apply(lambda x: \"/content/no_cough_data_valid/\"+os.path.basename(x))"
      ],
      "metadata": {
        "id": "ShWaAroQTz0t"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/no_cough_valid_features\n",
        "!mkdir -p /content/no_cough_valid_features\n",
        "%cd /content/kambria-challenge/generateMFCC/\n",
        "!java -cp lib/jlibrosa-1.1.8-SNAPSHOT-jar-with-dependencies.jar:bin com.example.Main /content/no_cough_data_valid /content/no_cough_valid_features 16000 120"
      ],
      "metadata": {
        "id": "BzDEHTBpUXNm"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "negative_df_valid[\"feature\"] = negative_df_valid[\"uuid\"].apply(readFeatures, features_dir=\"/content/no_cough_valid_features/\")"
      ],
      "metadata": {
        "id": "n09gFLGfTz38"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "final_aug_data_valid = pd.concat([positive_df_valid, negative_df_valid])\n",
        "final_aug_data_valid"
      ],
      "metadata": {
        "id": "QscRWngGVqGl"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "!rm -rf /content/cough_data_test\n",
        "!mkdir -p /content/cough_data_test\n",
        "for index, row in positive_df_test.iterrows():\n",
        "    src = row[\"audio_path\"]\n",
        "    dst = \"/content/cough_data_test/\"+row[\"uuid\"]+\".wav\"\n",
        "    copyfile(src, dst)\n",
        "positive_df_test['audio_path'] = positive_df_test['audio_path'].apply(lambda x: \"/content/cough_data_test/\"+os.path.basename(x))\n",
        "\n",
        "!rm -rf /content/cough_test_features\n",
        "!mkdir -p /content/cough_test_features\n",
        "%cd /content/kambria-challenge/generateMFCC/\n",
        "!java -cp lib/jlibrosa-1.1.8-SNAPSHOT-jar-with-dependencies.jar:bin com.example.Main /content/cough_data_test /content/cough_test_features 16000 120\n",
        "\n",
        "positive_df_test[\"feature\"] = positive_df_test[\"uuid\"].apply(readFeatures, features_dir=\"/content/cough_test_features/\")\n",
        "\n",
        "!rm -rf /content/no_cough_data_test\n",
        "!mkdir -p /content/no_cough_data_test\n",
        "for index, row in negative_df_test.iterrows():\n",
        "    src = row[\"audio_path\"]\n",
        "    dst = \"/content/no_cough_data_test/\"+row[\"uuid\"]+\".wav\"\n",
        "    copyfile(src, dst)\n",
        "negative_df_test['audio_path'] = negative_df_test['audio_path'].apply(lambda x: \"/content/no_cough_data_test/\"+os.path.basename(x))\n",
        "\n",
        "!rm -rf /content/no_cough_test_features\n",
        "!mkdir -p /content/no_cough_test_features\n",
        "%cd /content/kambria-challenge/generateMFCC/\n",
        "!java -cp lib/jlibrosa-1.1.8-SNAPSHOT-jar-with-dependencies.jar:bin com.example.Main /content/no_cough_data_test /content/no_cough_test_features 16000 120\n",
        "\n",
        "negative_df_test[\"feature\"] = negative_df_test[\"uuid\"].apply(readFeatures, features_dir=\"/content/no_cough_test_features/\")\n",
        "\n",
        "final_aug_data_test = pd.concat([positive_df_test, negative_df_test])\n",
        "final_aug_data_test"
      ],
      "metadata": {
        "id": "5-XTbKVroxDj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Training"
      ],
      "metadata": {
        "id": "4GGgroOr2OVU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "def create_cnn():\n",
        "    model = Sequential()\n",
        "    model.add(Conv2D(16, (7,7), input_shape=(num_rows, num_columns, num_channels), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(32, (3,3), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(64, (3,3), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(128, (3,3), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(256, (3,3), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(Conv2D(512, (1,1), activation='relu', padding=\"same\"))\n",
        "    model.add(BatchNormalization())\n",
        "    model.add(GlobalAveragePooling2D())\n",
        "    model.add(Dense(1, activation='sigmoid'))\n",
        "    return model"
      ],
      "metadata": {
        "id": "SKV4TBteV-Sc"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "class DataGenerator(Sequence):\n",
        "    def __init__(self,\n",
        "                _X,\n",
        "                batch_size=32,\n",
        "                n_channels=1,\n",
        "                n_columns=470,\n",
        "                n_rows=120,\n",
        "                shuffle=True):\n",
        "        self.batch_size = batch_size\n",
        "        self.X = _X\n",
        "        self.n_channels = n_channels\n",
        "        self.n_columns = n_columns\n",
        "        self.n_rows = n_rows\n",
        "        self.shuffle = shuffle\n",
        "        self.img_indexes = np.arange(len(self.X))\n",
        "        self.on_epoch_end()\n",
        "        \n",
        "    def __len__(self):\n",
        "        'Denotes the number of batches per epoch'\n",
        "        return int(np.floor(len(self.img_indexes) / self.batch_size))\n",
        "\n",
        "    def __getitem__(self, index):\n",
        "        'Generate one batch of data'\n",
        "        # Generate indexes of the batch\n",
        "        indexes = self.indexes[index*self.batch_size:(index+1)*self.batch_size]\n",
        "        # Find list of IDs\n",
        "        list_IDs_temps = [self.img_indexes[k] for k in indexes]\n",
        "\n",
        "        # Generate data\n",
        "        X, y = self.__data_generation(list_IDs_temps)\n",
        "        return X, y\n",
        "\n",
        "    def on_epoch_end(self):\n",
        "        'Updates indexes after each epoch'\n",
        "        self.indexes = np.arange(len(self.X))\n",
        "        if self.shuffle == True:\n",
        "            np.random.shuffle(self.indexes)\n",
        "\n",
        "    def __data_generation(self, list_IDs_temps):\n",
        "        X = np.empty((self.batch_size, self.n_rows, self.n_columns))\n",
        "        y = np.empty((self.batch_size), dtype=int)\n",
        "        for i, ID in enumerate(list_IDs_temps):\n",
        "            x_features = self.X.iloc[ID][\"feature\"]\n",
        "            label = self.X.iloc[ID][\"assessment_result\"]\n",
        "            X[i] = x_features\n",
        "            y[i] = label\n",
        "        X = X.reshape(X.shape[0], self.n_rows, self.n_columns, self.n_channels)\n",
        "        return X, y"
      ],
      "metadata": {
        "id": "b9MCH_f2XNYH"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = dict(\n",
        "    batch_size=16,\n",
        "    n_rows=num_rows,\n",
        "    n_columns=num_columns,\n",
        "    n_channels=num_channels,\n",
        ")\n",
        "params_train = dict(\n",
        "    shuffle=True,\n",
        "    **params\n",
        ")\n",
        "params_valid = dict(\n",
        "    shuffle=False,\n",
        "    **params\n",
        ")"
      ],
      "metadata": {
        "id": "Ukv8OWdRXQPj"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import matplotlib.pyplot as plt\n",
        "\n",
        "def plot_his(history):\n",
        "    plt.figure(1, figsize = (15,8))\n",
        "    plt.subplot(221)\n",
        "    plt.plot(history.history['accuracy'])\n",
        "    plt.plot(history.history['val_accuracy'])\n",
        "    plt.title('model accuracy')\n",
        "    plt.ylabel('accuracy')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'valid'])\n",
        "    plt.subplot(222)\n",
        "    plt.plot(history.history['loss'])\n",
        "    plt.plot(history.history['val_loss'])\n",
        "    plt.title('model loss')\n",
        "    plt.ylabel('loss')\n",
        "    plt.xlabel('epoch')\n",
        "    plt.legend(['train', 'valid'])\n",
        "    plt.show()"
      ],
      "metadata": {
        "id": "B2USXUIqXNbC"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "checkpoint_model_path = \"/content/cough_detection.hdf5\"\n",
        "\n",
        "def train_model(model, train_gen, val_gen, fold):    \n",
        "    metric = \"val_loss\"\n",
        "    print(\"METRIC:\", metric)\n",
        "\n",
        "    model.compile(optimizer=tf.keras.optimizers.Adam(learning_rate=0.001), loss='binary_crossentropy', metrics=[\"accuracy\"])\n",
        "\n",
        "    num_epochs = 100\n",
        "\n",
        "    checkpointer = ModelCheckpoint(\n",
        "        filepath=checkpoint_model_path,\n",
        "        monitor=metric, verbose=1, save_best_only=True)\n",
        "    es_callback = EarlyStopping(monitor=metric, patience=10, verbose=1)\n",
        "    reduce_lr = ReduceLROnPlateau(monitor=metric, factor=0.3, patience=1, verbose=1, min_delta=0.0001, cooldown=1, min_lr=0.00001)\n",
        "\n",
        "    history = model.fit(\n",
        "        train_gen,\n",
        "        epochs=num_epochs,\n",
        "        validation_data=val_gen,\n",
        "        callbacks=[checkpointer,es_callback,reduce_lr],\n",
        "        verbose=1\n",
        "    )\n",
        "\n",
        "    plot_his(history)"
      ],
      "metadata": {
        "id": "dA99SO_TXNd5"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "X_valid = final_aug_data_valid\n",
        "X_train = final_aug_data\n",
        "train_generator = DataGenerator(X_train, **params_train)\n",
        "valid_generator = DataGenerator(X_valid, **params_valid)\n",
        "cnn_model = create_cnn()\n",
        "train_model(cnn_model, train_generator, valid_generator)"
      ],
      "metadata": {
        "id": "XKDnOBpKXNgf"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "### Infer"
      ],
      "metadata": {
        "id": "YwYHF5AT58AV"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "infer_df = final_aug_data_test\n",
        "infer_df"
      ],
      "metadata": {
        "id": "yyytNNf4uYCv"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "infer_df[\"assessment_result\"].value_counts()"
      ],
      "metadata": {
        "id": "Vb5FkU51x83m"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "params = dict(\n",
        "    batch_size=1,\n",
        "    n_rows=num_rows,\n",
        "    n_columns=num_columns,\n",
        "    n_channels=num_channels,\n",
        ")\n",
        "params_valid = dict(\n",
        "    shuffle=False,\n",
        "    **params\n",
        ")\n",
        "full_gen = DataGenerator(infer_df, **params_valid)\n",
        "\n",
        "pred_models = []\n",
        "cnn_model = create_cnn(\"mobilenet\")\n",
        "cnn_model.load_weights(checkpoint_model_path)\n",
        "y_preds = cnn_model.predict(full_gen)\n",
        "predictions = [p[0] for p in y_preds]\n",
        "pred_models.append(predictions)"
      ],
      "metadata": {
        "id": "jl3JDCn6uW76"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "infer_df[\"pred\"] = np.average(pred_models, axis=0)\n",
        "from sklearn.metrics import classification_report\n",
        "print(classification_report(infer_df[\"assessment_result\"], np.round(infer_df[\"pred\"]), target_names=[\"not_cough\", \"cough\"]))"
      ],
      "metadata": {
        "id": "tQLtXH4wuo_1"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}